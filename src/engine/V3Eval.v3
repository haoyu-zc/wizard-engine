// Copyright 2022 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// The {V3Eval} component contains canonical Virgil-level implementations of many Wasm operations.
// These operations work on Virgil-level values like {u32} and {float}, not boxed {Value}s so they
// can be reused in multiple different ways.
// For example, the {V3Interpreter} handles value stacks and boxes but ultimate calls these
// routines, and the compiler(s) use these routines during constant-folding, thus guaranteeing
// the same semantics.
component V3Eval {
	// ---- i32 comparisons ------------------------------------------------
	def I32_EQZ	= u32.==(0, _);
	def I32_EQ	= u32.==;
	def I32_NE	= u32.!=;
	def I32_LT_S	= i32.<;
	def I32_LT_U	= u32.<;
	def I32_GT_S	= i32.>;
	def I32_GT_U	= u32.>;
	def I32_LE_S	= i32.<=;
	def I32_LE_U	= u32.<=;
	def I32_GE_S	= i32.>=;
	def I32_GE_U	= u32.>=;

	// ---- i64 comparisons ------------------------------------------------
	def I64_EQZ	= u64.==(0, _);
	def I64_EQ	= u64.==;
	def I64_NE	= u64.!=;
	def I64_LT_S	= i64.<;
	def I64_LT_U	= u64.<;
	def I64_GT_S	= i64.>;
	def I64_GT_U	= u64.>;
	def I64_LE_S	= i64.<=;
	def I64_LE_U	= u64.<=;
	def I64_GE_S	= i64.>=;
	def I64_GE_U	= u64.>=;

	// ---- f32 comparisons ------------------------------------------------
	def F32_EQ	= float.==;
	def F32_NE	= float.!=;
	def F32_LT	= float.<;
	def F32_GT	= float.>;
	def F32_LE	= float.<=;
	def F32_GE	= float.>=;

	// ---- f64 comparisons ------------------------------------------------
	def F64_EQ	= double.==;
	def F64_NE	= double.!=;
	def F64_LT	= double.<;
	def F64_GT	= double.>;
	def F64_LE	= double.<=;
	def F64_GE	= double.>=;

	// ---- i32 arithmetic -------------------------------------------------
	def I32_CLZ(x: u32) -> u32 {
		var count = 0u;
		if (x == 0) return 32;
		while ((x & 0x80000000u) == 0) { count++; x <<= 1; }
		return count;
	}
	def I32_CTZ(x: u32) -> u32 {
		var count = 0u;
		if (x == 0) return 32;
		while ((x & 1u) == 0) { count++; x >>= 1; }
		return count;
	}
	def I32_POPCNT(x: u32) -> u32 {
		var count = 0u;
		for (i < 32) {
			if ((x & 1) == 1) count++;
			x >>= 1;
		}
		return count;
	}
	def I32_ADD	= u32.+;
	def I32_SUB	= u32.-;
	def I32_MUL	= u32.*;
	def I32_DIV_S(x: i32, y: i32) -> (i32, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		if (y == -1 && x == int.min) return (0, TrapReason.DIV_UNREPRESENTABLE);
		return (x / y, TrapReason.NONE);
	}
	def I32_DIV_U(x: u32, y: u32) -> (u32, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		return (x / y, TrapReason.NONE);
	}
	def I32_REM_S(x: i32, y: i32) -> (i32, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		return (if (y == -1, 0, x % y), TrapReason.NONE);
	}
	def I32_REM_U(x: u32, y: u32) -> (u32, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		return (if(y == 1, 0, x % y), TrapReason.NONE);
	}
	def I32_AND	= u32.&;
	def I32_OR	= u32.|;
	def I32_XOR	= u32.^;
	def I32_SHL(x: i32, y: i32) -> i32 {
		return x << u5.view(y);
	}
	def I32_SHR_S(x: i32, y: i32) -> i32 {
		return x >> u5.view(y);
	}
	def I32_SHR_U(x: i32, y: i32) -> i32 {
		return x >>> u5.view(y);
	}
	def I32_ROTL(x: u32, z: u32) -> u32 {
		var y = u5.view(z);
		if (y != 0) {
			var upper = x << y;
			var lower = x >> byte.view(32) - y;
			x = upper | lower;
		}
		return x;
	}
	def I32_ROTR(x: u32, z: u32) -> u32 {
		var y = u5.view(z);
		if (y != 0) {
			var upper = x << byte.view(32) - y;
			var lower = x >> y;
			x = upper | lower;
		}
		return x;
	}

	// ---- i64 arithmetic -------------------------------------------------
	def I64_CLZ(x: u64) -> u64 {
		var count = 0u;
		if (x == 0) return 64;
		while ((x & 0x8000000000000000ul) == 0) { count++; x <<= 1; }
		return count;
	}
	def I64_CTZ(x: u64) -> u64 {
		var count = 0u;
		if (x == 0) return 64;
		while ((x & 1u) == 0) { count++; x >>= 1; }
		return count;
	}
	def I64_POPCNT(x: u64) -> u64 {
		var count = 0u;
		for (i < 64) {
			if ((x & 1) == 1) count++;
			x >>= 1;
		}
		return count;
	}
	def I64_ADD	= u64.+;
	def I64_SUB	= u64.-;
	def I64_MUL	= u64.*;
	def I64_DIV_S(x: i64, y: i64) -> (i64, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		if (y == -1 && x == long.min) return (0, TrapReason.DIV_UNREPRESENTABLE);
		return (x / y, TrapReason.NONE);
	}
	def I64_DIV_U(x: u64, y: u64) -> (u64, TrapReason) {
		if (y == 0) return(0, TrapReason.DIV_BY_ZERO);
		return (x / y, TrapReason.NONE);
	}
	def I64_REM_S(x: i64, y: i64) -> (i64, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		return (if(y == -1, 0, x % y), TrapReason.NONE);
	}
	def I64_REM_U(x: u64, y: u64) -> (u64, TrapReason) {
		if (y == 0) return (0, TrapReason.DIV_BY_ZERO);
		return (if(y == 1, 0, x % y), TrapReason.NONE);
	}
	def I64_AND	= u64.&;
	def I64_OR	= u64.|;
	def I64_XOR	= u64.^;
	def I64_SHL(x: u64, y: u64) -> u64 {
		return x << u6.view(y);
	}
	def I64_SHR_S(x: i64, y: i64) -> i64 {
		return x >> u6.view(y);
	}
	def I64_SHR_U(x: u64, y: u64) -> u64 {
		return x >> u6.view(y);
	}
	def I64_ROTL(x: u64, z: u64) -> u64 {
		var y = u6.view(z);
		if (y != 0) {
			var upper = x << y;
			var lower = x >> byte.view(64) - y;
			x = upper | lower;
		}
		return x;
	}
	def I64_ROTR(x: u64, z: u64) -> u64 {
		var y = u6.view(z);
		if (y != 0) {
			var upper = x << byte.view(64) - y;
			var lower = x >> y;
			x = upper | lower;
		}
		return x;
	}

	// ---- f32 arithmetic -------------------------------------------------
	def F32_ABS	= float.abs;
	def F32_NEG(a: float) -> float {
		return float.view(0x80000000u ^ u32.view(a));
	}
	def F32_CEIL(a: float) -> float {
		return canonf(float.ceil(a));
	}
	def F32_FLOOR(a: float) -> float {
		return canonf(float.floor(a));
	}
	def F32_TRUNC(a: float) -> float {
		if (a < 0f) {
			if (a > -1f) return -0f;  // handle -0
			return 0f - float.floor(0f - a);
		}
		return canonf(float.floor(a));
	}
	def F32_NEAREST	= float.round;
	def F32_SQRT	= float.sqrt;
	def F32_ADD	= float.+;
	def F32_SUB	= float.-;
	def F32_MUL	= float.*;
	def F32_DIV	= float./;
	def F32_MIN(a: float, b: float) -> float {
		if (a < b) return a;
		if (a == b) return if(b.sign == 1, b, a); // handle -0
		if (b < a) return b;
		return float.nan;
	}
	def F32_MAX(a: float, b: float) -> float {
		if (a > b) return a;
		if (a == b) return if(b.sign == 0, b, a); // handle -0
		if (b > a) return b;
		return float.nan;
	}
	def F32_COPYSIGN(a: float, b: float) -> float {
		var aa = 0x7fffffffu & u32.view(a);
		var bb = 0x80000000u & u32.view(b);
		return float.view(aa | bb);
	}

	// ---- f64 arithmetic -------------------------------------------------
	def F64_ABS	= double.abs;
	def F64_NEG(a: double) -> double {
		return double.view(0x8000000000000000uL ^ u64.view(a));
	}
	def F64_CEIL(a: double) -> double {
		return canond(double.ceil(a));
	}
	def F64_FLOOR(a: double) -> double {
		return canond(double.floor(a));
	}
	def F64_TRUNC(a: double) -> double {
		if (a < 0d) {
			if (a > -1d) return -0d;  // handle -0
			return 0d - double.floor(0d - a);
		}
		return canond(double.floor(a));
	}
	def F64_NEAREST	= double.round;
	def F64_SQRT	= double.sqrt;
	def F64_ADD	= double.+;
	def F64_SUB	= double.-;
	def F64_MUL	= double.*;
	def F64_DIV	= double./;
	def F64_MIN(a: double, b: double) -> double {
		if (a < b) return a;
		if (a == b) return if(b.sign == 1, b, a); // handle -0
		if (b < a) return b;
		return double.nan;
	}
	def F64_MAX(a: double, b: double) -> double {
		if (a > b) return a;
		if (a == b) return if(b.sign == 0, b, a); // handle -0
		if (b > a) return b;
		return double.nan;
	}
	def F64_COPYSIGN(a: double, b: double) -> double {
		var aa = 0x7fffffffffffffffuL & u64.view(a);
		var bb = 0x8000000000000000uL & u64.view(b);
		return double.view(aa | bb);
	}

	// ---- v128 arithmetic ---------------------------------------------
	def V128_NOT = do_vv_v_x2(_, (u64.max, u64.max), u64.^);
	def V128_AND = do_vv_v_x2(_, _, u64.&);
	def V128_OR = do_vv_v_x2(_, _, u64.|);
	def V128_XOR = do_vv_v_x2(_, _, u64.^);
	def V128_BITSELECT(a: (u64, u64), b: (u64, u64), c: (u64, u64)) -> (u64, u64) {
		// Equivalent to v128.or(v128.and(a, c), v128.and(b, v128.not(c))).
		var not_c = V128_NOT(c);
		var and_ac = V128_AND(a, c);
		var and_b_not_c = V128_AND(b, not_c);
		return V128_OR(and_ac, and_b_not_c);
	}
	def V128_ANDNOT(a: (u64, u64), b: (u64, u64)) -> (u64, u64) {
		var not_b = V128_NOT(b);
		return V128_AND(a, not_b);
	}
	def I64X2_ADD= do_vv_v_x2(_, _, u64.+);
	def I64X2_SUB= do_vv_v_x2(_, _, u64.-);
	def I64X2_MUL= do_vv_v_x2(_, _, u64.*);
	def I64X2_NEG = do_vv_v_x2((0, 0), _, u64.-);
	def I64X2_ABS = do_v_v_x2(_, V128_I64_ABS);
	def I64X2_EQ = do_vv_v_x2(_, _, V128_I64X2_EQ);
	def I64X2_NE = do_vv_v_x2(_, _, V128_I64X2_NE);
	def I64X2_LT_S = do_vv_v_x2(_, _, V128_I64X2_LT_S);
	def I64X2_LE_S = do_vv_v_x2(_, _, V128_I64X2_LE_S);
	def I64X2_GT_S = commute_binop(I64X2_LT_S);
	def I64X2_GE_S = commute_binop(I64X2_LE_S);
	def I32X4_ADD = do_vv_v_x4(_, _, u32.+);
	def I32X4_SUB = do_vv_v_x4(_, _, u32.-);
	def I32X4_MUL = do_vv_v_x4(_, _, u32.*);
	def I32X4_NEG = do_vv_v_x4((0, 0), _, u32.-);
	def I32X4_MIN_S = do_vv_v_x4(_, _, V128_I32_MIN_S);
	def I32X4_MIN_U = do_vv_v_x4(_, _, I32_MIN_U);
	def I32X4_MAX_S = do_vv_v_x4(_, _, V128_I32_MAX_S);
	def I32X4_MAX_U = do_vv_v_x4(_, _, I32_MAX_U);
	def I32X4_ABS = do_v_v_x4(_, V128_I32_ABS);
	def I32X4_EQ = do_vv_v_x4(_, _, V128_I32X4_EQ);
	def I32X4_NE = do_vv_v_x4(_, _, V128_I32X4_NE);
	def I32X4_LT_S = do_vv_v_x4(_, _, V128_I32X4_LT_S);
	def I32X4_LT_U = do_vv_v_x4(_, _, V128_I32X4_LT_U);
	def I32X4_LE_S = do_vv_v_x4(_, _, V128_I32X4_LE_S);
	def I32X4_LE_U = do_vv_v_x4(_, _, V128_I32X4_LE_U);
	def I32X4_GT_S = commute_binop(I32X4_LT_S);
	def I32X4_GT_U = commute_binop(I32X4_LT_U);
	def I32X4_GE_S = commute_binop(I32X4_LE_S);
	def I32X4_GE_U = commute_binop(I32X4_LE_U);
	def I16X8_ADD = do_vv_v_x8(_, _, u16.+);
	def I16X8_SUB = do_vv_v_x8(_, _, u16.-);
	def I16X8_MUL = do_vv_v_x8(_, _, u16.*);
	def I16X8_Q15MULRSAT_S = do_vv_v_x8(_, _, V128_I16_Q15_MUL_SAT_S);
	def I16X8_NEG = do_vv_v_x8((0, 0), _, u16.-);
	def I16X8_ADD_SAT_S = do_vv_v_x8(_, _, V128_I16_ADD_SAT_S);
	def I16X8_ADD_SAT_U = do_vv_v_x8(_, _, I16_ADD_SAT_U);
	def I16X8_SUB_SAT_S = do_vv_v_x8(_, _, V128_I16_SUB_SAT_S);
	def I16X8_SUB_SAT_U = do_vv_v_x8(_, _, I16_SUB_SAT_U);
	def I16X8_MIN_S = do_vv_v_x8(_, _, V128_I16_MIN_S);
	def I16X8_MIN_U = do_vv_v_x8(_, _, I16_MIN_U);
	def I16X8_MAX_S = do_vv_v_x8(_, _, V128_I16_MAX_S);
	def I16X8_MAX_U = do_vv_v_x8(_, _, I16_MAX_U);
	def I16X8_AVGR_U = do_vv_v_x8(_, _, I16_AVGR_U);
	def I16X8_ABS = do_v_v_x8(_, V128_I16_ABS);
	def I16X8_EQ = do_vv_v_x8(_, _, V128_I16X8_EQ);
	def I16X8_NE = do_vv_v_x8(_, _, V128_I16X8_NE);
	def I16X8_LT_S = do_vv_v_x8(_, _, V128_I16X8_LT_S);
	def I16X8_LT_U = do_vv_v_x8(_, _, V128_I16X8_LT_U);
	def I16X8_LE_S = do_vv_v_x8(_, _, V128_I16X8_LE_S);
	def I16X8_LE_U = do_vv_v_x8(_, _, V128_I16X8_LE_U);
	def I16X8_GT_S = commute_binop(I16X8_LT_S);
	def I16X8_GT_U = commute_binop(I16X8_LT_U);
	def I16X8_GE_S = commute_binop(I16X8_LE_S);
	def I16X8_GE_U = commute_binop(I16X8_LE_U);
	def I8X16_ADD = do_vv_v_x16(_, _, u8.+);
	def I8X16_SUB = do_vv_v_x16(_, _, u8.-);
	def I8X16_NEG = do_vv_v_x16((0, 0), _, u8.-);
	def I8X16_ADD_SAT_S = do_vv_v_x16(_, _, V128_I8_ADD_SAT_S);
	def I8X16_ADD_SAT_U = do_vv_v_x16(_, _, I8_ADD_SAT_U);
	def I8X16_SUB_SAT_S = do_vv_v_x16(_, _, V128_I8_SUB_SAT_S);
	def I8X16_SUB_SAT_U = do_vv_v_x16(_, _, I8_SUB_SAT_U);
	def I8X16_MIN_S = do_vv_v_x16(_, _, V128_I8_MIN_S);
	def I8X16_MIN_U = do_vv_v_x16(_, _, I8_MIN_U);
	def I8X16_MAX_S = do_vv_v_x16(_, _, V128_I8_MAX_S);
	def I8X16_MAX_U = do_vv_v_x16(_, _, I8_MAX_U);
	def I8X16_AVGR_U = do_vv_v_x16(_, _, I8_AVGR_U);
	def I8X16_ABS = do_v_v_x16(_, V128_I8_ABS);
	def I8X16_POPCNT = do_v_v_x16(_, I8_POPCNT);
	def I8X16_EQ = do_vv_v_x16(_, _, V128_I8X16_EQ);
	def I8X16_NE = do_vv_v_x16(_, _, V128_I8X16_NE);
	def I8X16_LT_S = do_vv_v_x16(_, _, V128_I8X16_LT_S);
	def I8X16_LT_U = do_vv_v_x16(_, _, V128_I8X16_LT_U);
	def I8X16_LE_S = do_vv_v_x16(_, _, V128_I8X16_LE_S);
	def I8X16_LE_U = do_vv_v_x16(_, _, V128_I8X16_LE_U);
	def I8X16_GT_S = commute_binop(I8X16_LT_S);
	def I8X16_GT_U = commute_binop(I8X16_LT_U);
	def I8X16_GE_S = commute_binop(I8X16_LE_S);
	def I8X16_GE_U = commute_binop(I8X16_LE_U);
	def F32X4_ADD = do_vv_v_x4(_, _, F32_ADD_U);
	def F32X4_SUB = do_vv_v_x4(_, _, F32_SUB_U);
	def F32X4_MUL = do_vv_v_x4(_, _, F32_MUL_U);
	def F32X4_DIV = do_vv_v_x4(_, _, F32_DIV_U);
	def F32X4_NEG = do_v_v_x4(_, F32_NEG_U);
	def F32X4_SQRT = do_v_v_x4(_, F32_SQRT_U);
	def F32X4_EQ = do_vv_v_x4(_, _, V128_F32X4_EQ);
	def F32X4_NE = do_vv_v_x4(_, _, V128_F32X4_NE);
	def F32X4_LT = do_vv_v_x4(_, _, V128_F32X4_LT);
	def F32X4_LE = do_vv_v_x4(_, _, V128_F32X4_LE);
	def F32X4_GT = commute_binop(F32X4_LT);
	def F32X4_GE = commute_binop(F32X4_LE);
	def F32X4_MIN = do_vv_v_x4(_, _, V128_F32X4_MIN);
	def F32X4_MAX = do_vv_v_x4(_, _, V128_F32X4_MAX);
	def F32X4_ABS = do_v_v_x4(_, V128_F32X4_ABS);
	def F32X4_PMIN = do_vv_v_x4(_, _, V128_F32X4_PMIN);
	def F32X4_PMAX = do_vv_v_x4(_, _, V128_F32X4_PMAX);
	def F64X2_ADD = do_vv_v_x2(_, _, F64_ADD_U);
	def F64X2_SUB = do_vv_v_x2(_, _, F64_SUB_U);
	def F64X2_MUL = do_vv_v_x2(_, _, F64_MUL_U);
	def F64X2_DIV = do_vv_v_x2(_, _, F64_DIV_U);
	def F64X2_NEG = do_v_v_x2(_, F64_NEG_U);
	def F64X2_SQRT = do_v_v_x2(_, F64_SQRT_U);
	def F64X2_EQ = do_vv_v_x2(_, _, V128_F64X2_EQ);
	def F64X2_NE = do_vv_v_x2(_, _, V128_F64X2_NE);
	def F64X2_LT = do_vv_v_x2(_, _, V128_F64X2_LT);
	def F64X2_LE = do_vv_v_x2(_, _, V128_F64X2_LE);
	def F64X2_GT = commute_binop(F64X2_LT);	
	def F64X2_GE = commute_binop(F64X2_LE);
	def F64X2_MIN = do_vv_v_x2(_, _, V128_F64X2_MIN);
	def F64X2_MAX = do_vv_v_x2(_, _, V128_F64X2_MAX);
	def F64X2_ABS = do_v_v_x2(_, V128_F64X2_ABS);
	def F64X2_PMIN = do_vv_v_x2(_, _, V128_F64X2_PMIN);
	def F64X2_PMAX = do_vv_v_x2(_, _, V128_F64X2_PMAX);

	// ---- rounding and conversion ----------------------------------------
	def I32_WRAP_I64	= u32.view<u64>;
	def I32_TRUNC_F32_S	= truncF32(-2.1474839E9f, 2147483648f, i32.truncf, _);
	def I32_TRUNC_F32_U	= truncF32(-1f, 4294967296f, u32.truncf, _);
	def I32_TRUNC_F64_S	= truncF64(-2147483649d, 2147483648f, i32.truncd, _);
	def I32_TRUNC_F64_U	= truncF64(-1d, 4294967296d, u32.truncd, _);
	def I64_EXTEND_I32_S	= i64.view<i32>;
	def I64_EXTEND_I32_U	= u64.view<u32>;
	def I64_TRUNC_F32_S	= truncF32(-9.223373e18f, 9223372036854775808f, i64.truncf, _);
	def I64_TRUNC_F32_U	= truncF32(-1f, 18446744073709551616f, u64.truncf, _);
	def I64_TRUNC_F64_S	= truncF64(-9.223372036854778E18d, 9223372036854775808d, i64.truncd, _);
	def I64_TRUNC_F64_U	= truncF64(-1d, 18446744073709551616d, u64.truncd, _);
	def F32_CONVERT_I32_S	= float.roundi<i32>;
	def F32_CONVERT_I32_U	= float.roundi<u32>;
	def F32_CONVERT_I64_S	= float.roundi<i64>;
	def F32_CONVERT_I64_U	= float.roundi<u64>;
	def F32_DEMOTE_F64	= float.roundd;
	def F64_CONVERT_I32_S	= double.roundi<i32>;
	def F64_CONVERT_I32_U	= double.roundi<u32>;
	def F64_CONVERT_I64_S	= double.roundi<i64>;
	def F64_CONVERT_I64_U	= double.roundi<u64>;
	def F64_PROMOTE_F32	= double.!<float>;
	def I32_REINTERPRET_F32	= u32.view<float>;
	def I64_REINTERPRET_F64	= u64.view<double>;
	def F32_REINTERPRET_I32	= float.view<u32>;
	def F64_REINTERPRET_I64	= double.view<u64>;

	// ---- sign-extension and zero-extension helpers ----------------------
	def I32_EXTEND8_S(a: i32) -> i32 {
		return i8.view(a);
	}
	def I32_EXTEND16_S(a: i32) -> i32 {
		return i16.view(a);
	}
	def I64_EXTEND8_S(a: i64) -> i64 {
		return i8.view(a);
	}
	def I64_EXTEND16_S(a: i64) -> i64 {
		return i16.view(a);
	}
	def I64_EXTEND32_S(a: i64) -> i64 {
		return i32.view(a);
	}
	def signExtend(st: StorageType, val: Value) -> Value {
		match (st.packing) {
			PACKED_I8 => return Value.I32(u32.view(i8.view(Values.v_i(val))));
			PACKED_I16 => return Value.I32(u32.view(i16.view(Values.v_i(val))));
			_ => return val;
		}
	}
	def zeroExtend(st: StorageType, val: Value) -> Value {
		match (st.packing) {
			PACKED_I8 => return Value.I32(u8.view(Values.v_i(val)));
			PACKED_I16 => return Value.I32(u16.view(Values.v_i(val)));
			_ => return val;
		}
	}
}

// Private (i.e. file-scoped) utilities.
// ---- v128 arithmetic helpers ----------------------------------------
def F32_ADD_U = do_ff_f(_, _, float.+);
def F32_SUB_U = do_ff_f(_, _, float.-);
def F32_MUL_U = do_ff_f(_, _, float.*);
def F32_DIV_U = do_ff_f(_, _, float./);
def F32_NEG_U = do_f_f(_, V3Eval.F32_NEG);
def F32_SQRT_U = do_f_f(_, float.sqrt);
def F64_ADD_U = do_dd_d(_, _, double.+);
def F64_SUB_U = do_dd_d(_, _, double.-);
def F64_MUL_U = do_dd_d(_, _, double.*);
def F64_DIV_U = do_dd_d(_, _, double./);
def F64_NEG_U = do_d_d(_, V3Eval.F64_NEG);
def F64_SQRT_U = do_d_d(_, double.sqrt);

def V128_I8_MIN_S = do_ii_i_8(_, _, I8_MIN_S);
def V128_I16_MIN_S = do_ii_i_16(_, _, I16_MIN_S);
def V128_I32_MIN_S = do_ii_i(_, _, I32_MIN_S);
def V128_I8_MAX_S = do_ii_i_8(_, _, I8_MAX_S);
def V128_I16_MAX_S = do_ii_i_16(_, _, I16_MAX_S);
def V128_I32_MAX_S = do_ii_i(_, _, I32_MAX_S);
def V128_I8_ABS = do_i_i_8(_, I8_ABS_S);
def V128_I16_ABS = do_i_i_16(_, I16_ABS_S);
def V128_I32_ABS = do_i_i(_, I32_ABS_S);
def V128_I64_ABS = do_l_l(_, I64_ABS_S);

def V128_I8_ADD_SAT_S = do_ii_i_8(_, _, I8_ADD_SAT_S);
def V128_I8_SUB_SAT_S = do_ii_i_8(_, _, I8_SUB_SAT_S);
def V128_I16_ADD_SAT_S = do_ii_i_16(_, _, I16_ADD_SAT_S);
def V128_I16_SUB_SAT_S = do_ii_i_16(_, _, I16_SUB_SAT_S);
def V128_I8X16_EQ = do_uu_z_8(_, _, u8.==);
def V128_I8X16_NE = do_uu_z_8(_, _, u8.!=);
def V128_I8X16_LT_S = do_ii_z_8(_, _, i8.<);
def V128_I8X16_LT_U = do_uu_z_8(_, _, u8.<);
def V128_I8X16_LE_S = do_ii_z_8(_, _, i8.<=);
def V128_I8X16_LE_U = do_uu_z_8(_, _, u8.<=);
def V128_I16_Q15_MUL_SAT_S = do_ii_i_16(_, _, I16_Q15_MUL_SAT_S);
def V128_I16X8_EQ = do_uu_z_16(_, _, u16.==);
def V128_I16X8_NE = do_uu_z_16(_, _, u16.!=);
def V128_I16X8_LT_S = do_ii_z_16(_, _, i16.<);
def V128_I16X8_LT_U = do_uu_z_16(_, _, u16.<);
def V128_I16X8_LE_S = do_ii_z_16(_, _, i16.<=);
def V128_I16X8_LE_U = do_uu_z_16(_, _, u16.<=);
def V128_I32X4_EQ = do_uu_z(_, _, u32.==);
def V128_I32X4_NE = do_uu_z(_, _, u32.!=);
def V128_I32X4_LT_S = do_ii_z(_, _, i32.<);
def V128_I32X4_LT_U = do_uu_z(_, _, u32.<);
def V128_I32X4_LE_S = do_ii_z(_, _, i32.<=);
def V128_I32X4_LE_U = do_uu_z(_, _, u32.<=);
def V128_I64X2_EQ = do_ww_z(_, _, u64.==);
def V128_I64X2_NE = do_ww_z(_, _, u64.!=);
def V128_I64X2_LT_S = do_ll_z(_, _, i64.<);
def V128_I64X2_LE_S = do_ll_z(_, _, i64.<=);

def V128_F32X4_EQ = do_ff_z(_, _, float.==);
def V128_F32X4_NE = do_ff_z(_, _, float.!=);
def V128_F32X4_LT = do_ff_z(_, _, float.<);
def V128_F32X4_LE = do_ff_z(_, _, float.<=);
def V128_F32X4_MIN = do_ff_f(_, _, V3Eval.F32_MIN);
def V128_F32X4_MAX = do_ff_f(_, _, V3Eval.F32_MAX);
def V128_F32X4_ABS = do_f_f(_, float.abs);
def V128_F32X4_PMIN = do_ii_f(_, _, F32X4_PMIN);
def V128_F32X4_PMAX = do_ii_f(_, _, F32X4_PMAX);
def V128_F64X2_EQ = do_dd_z(_, _, double.==);
def V128_F64X2_NE = do_dd_z(_, _, double.!=);
def V128_F64X2_LT = do_dd_z(_, _, double.<);
def V128_F64X2_LE = do_dd_z(_, _, double.<=);
def V128_F64X2_MIN = do_dd_d(_, _, V3Eval.F64_MIN);
def V128_F64X2_MAX = do_dd_d(_, _, V3Eval.F64_MAX);
def V128_F64X2_ABS = do_d_d(_, double.abs);
def V128_F64X2_PMIN = do_dd_d(_, _, F64X2_PMIN);
def V128_F64X2_PMAX = do_dd_d(_, _, F64X2_PMAX);

def I8_MIN_S(a: i8, b: i8) -> i8 {
	return if (a <= b, a, b);
}
def I16_MIN_S(a: i16, b: i16) -> i16 {
	return 	if (a <= b, a, b);
}
def I32_MIN_S(a: i32, b: i32) -> i32 {
	return 	if (a <= b, a, b);
}
def I8_MAX_S(a: i8, b: i8) -> i8 {
	return 	if (a >= b, a, b);
}
def I16_MAX_S(a: i16, b: i16) -> i16 {
	return 	if (a >= b, a, b);
}
def I32_MAX_S(a: i32, b: i32) -> i32 {
	return 	if (a >= b, a, b);
}
def I8_MIN_U(a: u8, b: u8) -> u8 {
	return if (a <= b, a, b);
}
def I16_MIN_U(a: u16, b: u16) -> u16 {
	return if (a <= b, a, b);
}
def I32_MIN_U(a: u32, b: u32) -> u32 {
	return if (a <= b, a, b);
}
def I8_MAX_U(a: u8, b: u8) -> u8 {
	return if (a >= b, a, b);
}
def I16_MAX_U(a: u16, b: u16) -> u16 {
	return if (a >= b, a, b);
}
def I32_MAX_U(a: u32, b: u32) -> u32 {
	return if (a >= b, a, b);
}
def I8_AVGR_U(a: u8, b: u8) -> u8 {
	// rounding average
	var sum = u16.view(a) + u16.view(b);
	return u8.view((sum + 1) / 2);
}
def I16_AVGR_U(a: u16, b: u16) -> u16 {
	// rounding average
	var sum = u32.view(a) + u32.view(b);
	return u16.view((sum + 1) / 2);
}
def I8_ABS_S(a: i8) -> i8 {
	return if (a < 0, -a, a);
}
def I16_ABS_S(a: i16) -> i16 {
	return if (a < 0, -a, a);
}
def I32_ABS_S(a: i32) -> i32 {
	return if (a < 0, -a, a);
}
def I64_ABS_S(a: i64) -> i64 {
	return if (a < 0, -a, a);
}
def I8_POPCNT(a: u8) -> u8 {
	var count:byte = 0;
	for (i < 8) {
		if ((a & 1) == 1) count++;
		a >>= 1;
	}
	return count;
}
def I8_ADD_SAT_S(a: i8, b: i8) -> i8 {
	var sum = i16.view(a) + i16.view(b);
	if (sum > 127) return 127;
	else if (sum < -128) return -128;
	else return i8.view(sum);
}
def I8_ADD_SAT_U(a: u8, b: u8) -> u8 {
	var sum = u16.view(a) + u16.view(b);
	if (sum > 255) return 255;
	else return u8.view(sum);
}
def I8_SUB_SAT_S(a: i8, b: i8) -> i8 {
	var dif = i16.view(a) - i16.view(b);
	if (dif < i8.min) return i8.min;
	else if (dif > i8.max) return i8.max;
	else return i8.view(dif);
}
def I8_SUB_SAT_U(a: u8, b: u8) -> u8 {
	var dif = i16.view(a) - i16.view(b);
	if (dif < 0) return u8.view(0);
	else return u8.view(dif);
}
def I16_ADD_SAT_S(a: i16, b: i16) -> i16 {
	var sum = i32.view(a) + i32.view(b);
	if (sum > i16.max) return i16.max;
	else if (sum < i16.min) return i16.min;
	else return i16.view(sum);
}
def I16_ADD_SAT_U(a: u16, b: u16) -> u16 {
	var sum = u32.view(a) + u32.view(b);
	if (sum > u16.max) return u16.max;
	else return u16.view(sum);
}
def I16_SUB_SAT_S(a: i16, b: i16) -> i16 {
	var dif = i32.view(a) - i32.view(b);
	if (dif < i16.min) return i16.min;
	else if (dif > i16.max) return i16.max;
	else return i16.view(dif);
}
def I16_SUB_SAT_U(a: u16, b: u16) -> u16 {
	var dif = i32.view(a) - i32.view(b);
	if (dif < 0) return u16.view(0);
	else return u16.view(dif);
}
def I16_Q15_MUL_SAT_S(a: i16, b: i16) -> i16 {
	var prod = (i32.view(a) * i32.view(b) + 0x4000) >> 15;
	return if(prod > i16.max, i16.max, i16.view(prod));	
}
def F32X4_PMIN(a: float, b: float) -> float {
	if (a <= b) return a;
	if (a > b) return b;
	return a;
}
def F32X4_PMAX(a: float, b: float) -> float {
	if (a >= b) return a;
	if (a < b) return b;
	return a;
}
def F64X2_PMIN(a: double, b: double) -> double {
	if (a <= b) return a;
	if (a > b) return b;
	return a;
}
def F64X2_PMAX(a: double, b: double) -> double {
	if (a >= b) return a;
	if (a < b) return b;
	return a;
}
// Adapters
def do_uu_z_8(a: u8, b: u8, f: (u8, u8) -> bool) -> u8 {  // Adapts a unsigned bool binop to a u8 binop
	return if (f(a, b), u8.max, u8.view(0));
}
def do_uu_z_16(a: u16, b: u16, f: (u16, u16) -> bool) -> u16 {  // Adapts a unsigned bool binop to a u16 binop
	return if (f(a, b), u16.max, u16.view(0));
}
def do_uu_z(a: u32, b: u32, f: (u32, u32) -> bool) -> u32 {  // Adapts a unsigned bool binop to a u32 binop
	return if (f(a, b), u32.max, u32.view(0));
}
def do_ww_z(a: u64, b: u64, f: (u64, u64) -> bool) -> u64 {  // Adapts a unsigned bool binop to a u64 binop
	return if (f(a, b), u64.max, u64.view(0));
}
def do_ii_z_8(a: u8, b: u8, f: (i8, i8) -> bool) -> u8 {  // Adapts a signed bool binop to a u8 binop
	return if (f(i8.view(a), i8.view(b)), u8.max, u8.view(0));
}
def do_ii_z_16(a: u16, b: u16, f: (i16, i16) -> bool) -> u16 {  // Adapts a signed bool binop to a u16 binop
	return if (f(i16.view(a), i16.view(b)), u16.max, u16.view(0));
}
def do_ii_z(a: u32, b: u32, f: (i32, i32) -> bool) -> u32 {  // Adapts a signed bool binop to a u32 binop
	return if (f(i32.view(a), i32.view(b)), u32.max, u32.view(0));
}
def do_ll_z(a: u64, b: u64, f: (i64, i64) -> bool) -> u64 {  // Adapts a signed bool binop to a u64 binop
	return if (f(i64.view(a), i64.view(b)), u64.max, u64.view(0));
}
def do_ff_z(a: u32, b: u32, f: (float, float) -> bool) -> u32 {  // Adapts a floating point bool binop to a u32 binop
	return if (f(float.view(a), float.view(b)), u32.max, u32.view(0));
}
def do_dd_z(a: u64, b: u64, f: (double, double) -> bool) -> u64 {  // Adapts a floating point bool binop to a u64 binop
	return if (f(double.view(a), double.view(b)), u64.max, u64.view(0));
}
def do_ff_f(a: u32, b: u32, f: (float, float) -> float) -> u32 {  // Adapts a floating point binop to a u32 binop
	return u32.view(f(float.view(a), float.view(b)));
}
def do_f_f(a: u32, f: float -> float) -> u32 {  // Adapts a floating point unop to a u32 unop
	return u32.view(f(float.view(a)));
}
def do_dd_d(a: u64, b: u64, f: (double, double) -> double) -> u64 {  // Adapts a floating point binop to a u64 binop
	return u64.view(f(double.view(a), double.view(b)));
}
def do_d_d(a: u64, f: double -> double) -> u64 {  // Adapts a floating point unop to a u64 unop
	return u64.view(f(double.view(a)));
}
def do_ii_i_8(a: u8, b: u8, f: (i8, i8) -> i8) -> u8 {  // Adapts a signed i8 binop to a u8 binop
	return u8.view(f(i8.view(a), i8.view(b)));
}
def do_i_i_8(a: u8, f: i8 -> i8) -> u8 {  // Adapts a signed i8 unop to a u8 unop
	return u8.view(f(i8.view(a)));
}
def do_ii_i_16(a: u16, b: u16, f: (i16, i16) -> i16) -> u16 {  // Adapts a signed i16 binop to a u16 binop
	return u16.view(f(i16.view(a), i16.view(b)));
}
def do_i_i_16(a: u16, f: i16 -> i16) -> u16 {  // Adapts a signed i16 unop to a u16 unop
	return u16.view(f(i16.view(a)));
}
def do_ii_i(a: u32, b: u32, f: (i32, i32) -> i32) -> u32 {  // Adapts a signed i32 binop to a u32 binop
	return u32.view(f(i32.view(a), i32.view(b)));
}
def do_i_i(a: u32, f: i32 -> i32) -> u32 {  // Adapts a signed i32 unop to a u32 unop
	return u32.view(f(i32.view(a)));
}
def do_ii_f(a: u32, b: u32, f: (float, float) -> float) -> u32 {  // Adapts a signed i32 binop to a float binop
	var fa = float.view(i32.view(a));
	var fb = float.view(i32.view(b));
	var res = f(fa, fb);
	return u32.view(res);
}
def do_ll_l(a: u64, b: u64, f: (i64, i64) -> i64) -> u64 {  // Adapts a signed i64 binop to a u64 binop
	return u64.view(f(i64.view(a), i64.view(b)));
}
def do_l_l(a: u64, f: i64 -> i64) -> u64 {  // Adapts a signed i64 unop to a u64 unop
	return u64.view(f(i64.view(a)));
}
// Unary v128 ops
def do_v_v_x2(a: (u64, u64), f: (u64) -> u64) -> (u64, u64) { // Performs a 2-lane unop
	var r0 = f(a.0);
	var r1 = f(a.1);
	return (r0, r1);
}
def do_v_v_x4(a: (u64, u64), f: (u32) -> u32) -> (u64, u64) { // Performs a 4-lane unop
	var r0 = f(u32.view(a.0));
	var r1 = f(u32.view(a.0 >> 32));
	var r2 = f(u32.view(a.1));
	var r3 = f(u32.view(a.1 >> 32));
	return ((u64.view(r1) << 32) | r0, (u64.view(r3) << 32) | r2);
}
def do_v_v_x8(a: (u64, u64), f: (u16) -> u16) -> (u64, u64) { // Performs an 8-lane unop
	var low: u64 = 0;
	var high: u64 = 0;

	for (shift: byte = 0; shift < 64; shift += 16) {
		var r_a = u16.view((a.0 >> shift) & 0xFFFF);
		var res = f(r_a);
		low |= (u64.view(res) << shift);
		
		r_a = u16.view((a.1 >> shift) & 0xFFFF);
		res = f(r_a);
		high |= (u64.view(res) << shift);
	}

	return (low, high);
}
def do_v_v_x16(a: (u64, u64), f: (u8) -> u8) -> (u64, u64) { // Performs a 16-lane unop
	var low: u64 = 0;
	var high: u64 = 0;

	for (shift: byte = 0; shift < 64; shift += 8) {
		var r_a = u8.view((a.0 >> shift) & 0xFF);
		var res = f(r_a);
		low |= (u64.view(res) << shift);
		
		r_a = u8.view((a.1 >> shift) & 0xFF);
		res = f(r_a);
		high |= (u64.view(res) << shift);
	}

	return (low, high);
}
// Binary v128 ops
def do_vv_v_x2(a: (u64, u64), b: (u64, u64), f: (u64, u64) -> u64) -> (u64, u64) { // Performs a 2-lane binop
	var r0 = f(a.0, b.0);
	var r1 = f(a.1, b.1);
	return (r0, r1);
}
def do_vv_v_x4(a: (u64, u64), b: (u64, u64), f: (u32, u32) -> u32) -> (u64, u64) { // Performs a 4-lane binop
	var r0 = f(u32.view(a.0), u32.view(b.0));
	var r1 = f(u32.view(a.0 >> 32), u32.view(b.0 >> 32));
	var r2 = f(u32.view(a.1), u32.view(b.1));
	var r3 = f(u32.view(a.1 >> 32), u32.view(b.1 >> 32));
	return ((u64.view(r1) << 32) | r0, (u64.view(r3) << 32) | r2);
}
def do_vv_v_x8(a: (u64, u64), b: (u64, u64), f: (u16, u16) -> u16) -> (u64, u64) { // Performs an 8-lane binop
	var low: u64 = 0;
	var high: u64 = 0;
		for (shift: byte = 0; shift < 64; shift += 16) {
		var r_a = u16.view((a.0 >> shift) & 0xFFFF);
		var r_b = u16.view((b.0 >> shift) & 0xFFFF);
		var res = f(r_a, r_b);
		low |= (u64.view(res) << shift);
		
		r_a = u16.view((a.1 >> shift) & 0xFFFF);
		r_b = u16.view((b.1 >> shift) & 0xFFFF);
		res = f(r_a, r_b);
		high |= (u64.view(res) << shift);
	}
		return (low, high);
}
def do_vv_v_x16(a: (u64, u64), b: (u64, u64), f: (u8, u8) -> u8) -> (u64, u64) { // Performs a 16-lane binop
	var low: u64 = 0;
	var high: u64 = 0;
		for (shift: byte = 0; shift < 64; shift += 8) {
		var r_a = u8.view((a.0 >> shift) & 0xFF);
		var r_b = u8.view((b.0 >> shift) & 0xFF);
		var res = f(r_a, r_b);
		low |= (u64.view(res) << shift);
		
		r_a = u8.view((a.1 >> shift) & 0xFF);
		r_b = u8.view((b.1 >> shift) & 0xFF);
		res = f(r_a, r_b);
		high |= (u64.view(res) << shift);
	}
		return (low, high);
}
// Helper to commute a binary operation
def commute_binop<T, R>(f: (T, T) -> R) -> (T, T) -> R {
	return commute_binop0(f, _, _);
}
def commute_binop0<T, R>(f: (T, T) -> R, a: T, b: T) -> R {
	return f(b, a);
}
def canonf(a: float) -> float {
	return if(a == a, a, float.nan);
}
def canond(a: double) -> double {
	return if(a == a, a, double.nan);
}
def truncF32<T>(min: float, max: float, trunc: float -> T, a: float) -> (T, TrapReason) {
	var d: T;
	if (a >= max) return (d, TrapReason.FLOAT_UNREPRESENTABLE);
	if (a <= min) return (d, TrapReason.FLOAT_UNREPRESENTABLE);
	if (!(a == a)) return (d, TrapReason.FLOAT_UNREPRESENTABLE);
	return (trunc(a), TrapReason.NONE);
}
def truncF64<T>(min: double, max: double, trunc: double -> T, a: double) -> (T, TrapReason) {
	var d: T;
	if (a >= max) return (d, TrapReason.FLOAT_UNREPRESENTABLE);
	if (a <= min) return (d, TrapReason.FLOAT_UNREPRESENTABLE);
	if (!(a == a)) return (d, TrapReason.FLOAT_UNREPRESENTABLE);
	return (trunc(a), TrapReason.NONE);
}
